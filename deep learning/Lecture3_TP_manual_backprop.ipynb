{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/prabal5ghosh/UCA-M2-SEMESTER1/blob/main/deep%20learning/Lecture3_TP_manual_backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbzBJ1m9FBBb"
   },
   "source": [
    "<center><h1>TP: Manual backprop</h1></center>\n",
    "\n",
    "# Warning :\n",
    "# \"File -> Save a copy in Drive\" before starting to modify the notebook, otherwise changes won't be saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfnKy8NB8J5e",
    "outputId": "8f5f38cb-613c-4044-920e-75ea527865f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-15 13:48:56--  https://remysun.github.io/uploads/TPBackprop.zip\n",
      "Resolving remysun.github.io (remysun.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
      "Connecting to remysun.github.io (remysun.github.io)|185.199.108.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13423382 (13M) [application/zip]\n",
      "Saving to: ‘TPBackprop.zip’\n",
      "\n",
      "TPBackprop.zip      100%[===================>]  12.80M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2024-10-15 13:48:57 (142 MB/s) - ‘TPBackprop.zip’ saved [13423382/13423382]\n",
      "\n",
      "Archive:  TPBackprop.zip\n",
      "  inflating: ._TP3-4                 \n",
      "  inflating: circles.mat             \n",
      "  inflating: ._circles.mat           \n",
      "  inflating: mnist.mat               \n",
      "  inflating: ._mnist.mat             \n",
      "--2024-10-15 13:48:57--  https://remysun.github.io/uploads/utils-data.py\n",
      "Resolving remysun.github.io (remysun.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
      "Connecting to remysun.github.io (remysun.github.io)|185.199.108.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3950 (3.9K) [application/octet-stream]\n",
      "Saving to: ‘utils-data.py’\n",
      "\n",
      "utils-data.py       100%[===================>]   3.86K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-15 13:48:57 (51.8 MB/s) - ‘utils-data.py’ saved [3950/3950]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://remysun.github.io/uploads/TPBackprop.zip\n",
    "!unzip -j TPBackprop.zip\n",
    "!wget https://remysun.github.io/uploads/utils-data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2vQ_LLdx8J5b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# %run 'utils-data.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48x_ha7f8J5i"
   },
   "source": [
    "# Part 1 : Forward et Backward\n",
    "\n",
    "Complete the function init_params to initialize the weights and store them in a dictionary. All weights should be initialized following a normal law with mean 0 and standard deviation 0.3.\n",
    "Hint: Use torch.randn and torch.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GtizX1JV8J5n"
   },
   "outputs": [],
   "source": [
    "def init_params(nx, nh, ny):\n",
    "    \"\"\"\n",
    "    nx, nh, ny: integers\n",
    "    out params: dictionnary\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "\n",
    "    #####################\n",
    "    ## Votre code ici  ##\n",
    "    #####################\n",
    "    # remplir avec les paramètres Wh, Wy, bh, by\n",
    "\n",
    "    params[\"Wh\"] = torch.randn(nx,nh)*0.3\n",
    "    params[\"Wy\"] = torch.randn(nh,ny)*0.3\n",
    "    params[\"bh\"] = torch.zeros(nh)\n",
    "    params[\"by\"] = torch.zeros(ny)\n",
    "\n",
    "    ####################\n",
    "    ##      FIN        #\n",
    "    ####################\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPdKZYDKpn7h"
   },
   "source": [
    "Complete the function forward to compute all the intermediary activations and the final output of the network given a batch of inputs X along with network weights params. The function should return a dictionary of intermediate steps and the output Y of the network.\n",
    "Hint: torch.mm implements matricial multiplication and torch.tanh, torch.exp, and torch.sum give useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUDJPuqUeDxy",
    "outputId": "50b1f30a-413c-411d-be64-8acee516e0a8"
   },
   "outputs": [],
   "source": [
    "params = init_params(2,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wh': tensor([[-0.1795, -0.0806,  0.0544,  0.2377],\n",
       "         [-0.1141, -0.4611, -0.1802,  0.3391]]),\n",
       " 'Wy': tensor([[ 0.1644, -0.5525,  0.5397, -0.0872],\n",
       "         [-0.0494,  0.6969, -0.5034,  0.3467],\n",
       "         [ 0.1103,  0.2610, -0.0564, -0.0442],\n",
       "         [-0.1534,  0.0746, -0.1625,  0.3523]]),\n",
       " 'bh': tensor([0., 0., 0., 0.]),\n",
       " 'by': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "jk-N_Ny67yo-"
   },
   "outputs": [],
   "source": [
    "def forward(params, X):\n",
    "    \"\"\"\n",
    "    params: dictionnary\n",
    "    X: (n_batch, dimension)\n",
    "    \"\"\"\n",
    "#     bsize = X.size(0)\n",
    "    bsize = X.size\n",
    "\n",
    "    nh = params['Wh'].size(0)\n",
    "    ny = params['Wy'].size(0)\n",
    "    outputs = {}\n",
    "\n",
    "    #####################\n",
    "    ## Votre code ici  ##\n",
    "    #####################\n",
    "    # remplir avec les paramètres X, htilde, h, ytilde, yhat\n",
    "\n",
    "    outputs[\"X\"] = X\n",
    "    print(X)\n",
    "    print(params[\"Wh\"])\n",
    "    print(params[\"bh\"])\n",
    "    print(torch.mm(X,params[\"Wh\"]. T))\n",
    "    \n",
    "    \n",
    "    outputs[\"htilde\"] = torch.mm(X,params[\"Wh\"]. T) + params[\"bh\"]\n",
    "    outputs[\"h\"] = torch.tanh(outputs[\"htilde\"])\n",
    "    outputs[\"ytilde\"] = torch.mm(outputs[\"h\"],params[\"Wy\"].T ) + params[\"by\"]\n",
    "    # outputs[\"yhat\"] = torch.nn.functional.softmax(input = outputs[\"ytilde\"])\n",
    "    x_exp = torch.exp(outputs[\"ytilde\"])\n",
    "    x_exp_sum = torch.sum(x_exp, 1, keepdim=True)\n",
    "    outputs[\"yhat\"] =x_exp/x_exp_sum\n",
    "\n",
    "    ####################\n",
    "    ##      FIN        #\n",
    "    ####################\n",
    "\n",
    "    return outputs['yhat'], outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wh': tensor([[-0.1795, -0.0806,  0.0544,  0.2377],\n",
       "         [-0.1141, -0.4611, -0.1802,  0.3391]]),\n",
       " 'Wy': tensor([[ 0.1644, -0.5525,  0.5397, -0.0872],\n",
       "         [-0.0494,  0.6969, -0.5034,  0.3467],\n",
       "         [ 0.1103,  0.2610, -0.0564, -0.0442],\n",
       "         [-0.1534,  0.0746, -0.1625,  0.3523]]),\n",
       " 'bh': tensor([0., 0., 0., 0.]),\n",
       " 'by': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPd2ByWvrBle"
   },
   "source": [
    "Complete loss_accuracy to compute the cost function and the accuracy of the model from a matrix Yhat of outputs with respect to a ground truth matrix Y, and return the loss and accuracy.\n",
    "Note: You should use the function _, indsY = torch.max(Y,1) to get the index of the predicted class for each sample.\n",
    "Hint: You might want to use torch.mean, torch.max, torch.log and torch.sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.1795, -0.0806,  0.0544,  0.2377],\n",
      "        [-0.1141, -0.4611, -0.1802,  0.3391]])\n",
      "tensor([0., 0., 0., 0.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: double != float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m forward(params,torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m1.0\u001b[39m]])))\n",
      "Cell \u001b[1;32mIn[43], line 22\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(params, X)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWh\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbh\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmm(X,params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWh\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39m T))\n\u001b[0;32m     25\u001b[0m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtilde\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(X,params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWh\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39m T) \u001b[38;5;241m+\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbh\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     26\u001b[0m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtilde\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: double != float"
     ]
    }
   ],
   "source": [
    "predictions = forward(params,torch.tensor(np.array([[0.0,0.0,0.0,1.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy(predictions, targets, epsilon = 1e-10):\n",
    "    # epsilon is added for numerical stability\n",
    "    predictions = np.clip(predictions, epsilon, 1.0- epsilon)\n",
    "    N= predictions.shape[0]\n",
    "    ce_loss = -np.sum(np.sum(targets * np.log(predictions+ 1e-5)))/ N\n",
    "    return ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.array([[0.00,0.00,0.40,0.60],[0.01,0.01,0.01,0.96]])\n",
    "# targets = np.array([[0,0,0,1],[0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-uB0A2b28NZK"
   },
   "outputs": [],
   "source": [
    "def loss_accuracy(Yhat, Y):\n",
    "\n",
    "    #####################\n",
    "    ## Votre code ici  ##\n",
    "    #####################\n",
    "\n",
    "    L = torch.nn.functional.cross_entropy(input= Yhat, target = Y)\n",
    "    acc = torch.sum(Yhat == Y)\n",
    "\n",
    "    ####################\n",
    "    ##      FIN        #\n",
    "    ####################\n",
    "\n",
    "    return L, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwcXkM5orm9u"
   },
   "source": [
    "Complete the backward function to compute the loss gradients with respect to the parameters, and store these gradients into the output dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWJjdiFe8qi5"
   },
   "outputs": [],
   "source": [
    "def backward(params, outputs, Y):\n",
    "    bsize = Y.shape[0]\n",
    "    grads = {}\n",
    "\n",
    "    #####################\n",
    "    ## Votre code ici  ##\n",
    "    #####################\n",
    "    # remplir avec les paramètres Wy, Wh, by, bh\n",
    "\n",
    "    grads[\"Wy\"] = None\n",
    "    grads[\"Wh\"] = None\n",
    "    grads[\"by\"] = None\n",
    "    grads[\"bh\"] = None\n",
    "\n",
    "    ####################\n",
    "    ##      FIN        #\n",
    "    ####################\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyiVD5fCr3Nr"
   },
   "source": [
    "Now apply the SGD steps in the sgd function to update the parameters given the computed gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAnsISsW9CnH"
   },
   "outputs": [],
   "source": [
    "def sgd(params, grads, eta):\n",
    "\n",
    "    #####################\n",
    "    ## Votre code ici  ##\n",
    "    #####################\n",
    "    # mettre à jour le contenu de params\n",
    "\n",
    "    params[\"Wh\"] = None\n",
    "    params[\"Wy\"] = None\n",
    "    params[\"bh\"] = None\n",
    "    params[\"by\"] = None\n",
    "\n",
    "    ####################\n",
    "    ##      FIN        #\n",
    "    ####################\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hifuW5UFA3DZ"
   },
   "source": [
    "## Algorithme global d'apprentissage (manuel)\n",
    "\n",
    "Fill in the forward, backward and SGD update calls in the training loop.\n",
    "Hint: The running batches Xtrain and Ytrain are already prepared for you in the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RSw6bd0-qUe"
   },
   "outputs": [],
   "source": [
    "# init\n",
    "data = CirclesData()\n",
    "data.plot_data()\n",
    "N = data.Xtrain.shape[0]\n",
    "Nbatch = 10\n",
    "nx = data.Xtrain.shape[1]\n",
    "nh = 10\n",
    "ny = data.Ytrain.shape[1]\n",
    "eta = 0.03\n",
    "\n",
    "params = init_params(nx, nh, ny)\n",
    "\n",
    "curves = [[],[], [], []]\n",
    "\n",
    "# epoch\n",
    "for iteration in range(150):\n",
    "\n",
    "    # permute\n",
    "    perm = np.random.permutation(N)\n",
    "    Xtrain = data.Xtrain[perm, :]\n",
    "    Ytrain = data.Ytrain[perm, :]\n",
    "\n",
    "    #####################\n",
    "    ## Votre code ici  ##\n",
    "    #####################\n",
    "    # batches\n",
    "    for j in range(N // Nbatch):\n",
    "\n",
    "        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n",
    "        X = Xtrain[indsBatch, :]\n",
    "        Y = Ytrain[indsBatch, :]\n",
    "\n",
    "        # écrire l'algorithme d'apprentissage sur le batch (X,Y)\n",
    "        # en utilisant les fonctions forward, loss_accuracy, backward, sgd\n",
    "\n",
    "\n",
    "    ####################\n",
    "    ##      FIN        #\n",
    "    ####################\n",
    "\n",
    "\n",
    "    Yhat_train, _ = forward(params, data.Xtrain)\n",
    "    Yhat_test, _ = forward(params, data.Xtest)\n",
    "    Ltrain, acctrain = loss_accuracy(Yhat_train, data.Ytrain)\n",
    "    Ltest, acctest = loss_accuracy(Yhat_test, data.Ytest)\n",
    "    Ygrid, _ = forward(params, data.Xgrid)\n",
    "\n",
    "    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n",
    "    print(title)\n",
    "    data.plot_data_with_grid(Ygrid, title)\n",
    "\n",
    "    curves[0].append(acctrain)\n",
    "    curves[1].append(acctest)\n",
    "    curves[2].append(Ltrain)\n",
    "    curves[3].append(Ltest)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(curves[0], label=\"acc. train\")\n",
    "plt.plot(curves[1], label=\"acc. test\")\n",
    "plt.plot(curves[2], label=\"loss train\")\n",
    "plt.plot(curves[3], label=\"loss test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xTIaiHwscxb"
   },
   "source": [
    "# Bonus: Try to add a third layer to the MLP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlnVnWekshBK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
